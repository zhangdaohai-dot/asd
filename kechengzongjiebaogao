\documentclass{article}
\usepackage[UTF8]{ctex}
\usepackage{geometry}
\usepackage{natbib}
\geometry{left=3.18cm,right=3.18cm,top=2.54cm,bottom=2.54cm}
\usepackage{graphicx}
\pagestyle{plain}	
\usepackage{setspace}
\usepackage{caption2}
\usepackage{datetime} %日期
\renewcommand{\today}{\number\year 年 \number\month 月 \number\day 日}
\renewcommand{\captionlabelfont}{\small}
\renewcommand{\captionfont}{\small}
\begin{document}

\begin{figure}
    \centering
    \includegraphics[width=8cm]{upc.png}

    \label{figupc}
\end{figure}

	\begin{center}
		\quad \\
		\quad \\
		\heiti \fontsize{45}{17} \quad \quad \quad 
		\vskip 1.5cm
		\heiti \zihao{2} 《计算科学导论》课程总结报告
	\end{center}
	\vskip 2.0cm
		
	\begin{quotation}
% 	\begin{center}
		\doublespacing
		
        \zihao{4}\par\setlength\parindent{7em}
		\quad 

		学生姓名：\underline{\qquad  张道海 \qquad \qquad}

		学\hspace{0.61cm} 号：\underline{\qquad 1907010206\qquad}
		
		专业班级：\underline{\qquad 计科1902 \qquad  }
		
        学\hspace{0.61cm} 院：\underline{计算机科学与技术学院}
% 	\end{center}
		\vskip 2cm
		\centering
		\begin{table}[h]
            \centering 
            \zihao{4}
            \begin{tabular}{|c|c|c|c|c|c|c|}
            % 这里的rl 与表格对应可以看到，姓名是r，右对齐的；学号是l，左对齐的；若想居中，使用c关键字。
                \hline
                课程认识 & 问题思 考 & 格式规范  & IT工具  & Latex附加  & 总分 & 评阅教师 \\
                30\% & 30\% & 20\% & 20\% & 10\% &  &  \\
                \hline
                 & & & & & &\\
                & & & & & &\\
                \hline
            \end{tabular}
        \end{table}
		\vskip 2cm
		\today
	\end{quotation}

\thispagestyle{empty}
\newpage
\setcounter{page}{1}
% 在这之前是封面，在这之后是正文
\section{引言}
在听了同学们的分组演讲之后，我对像区块链，比特币和人工智能等课题产生了一定的兴趣。其中我对人工智能最为感兴趣。为了加深我对于计算科学导论的理解和对于自己小组所选课题的认识以及由计算机到人工智能看法，特写此课程总结报告，总结自己所学，表达自己的看法与理解。

\section{对计算科学导论这门课程的认识、体会}
电子计算机的诞生和发展过程。电子计算机的诞生和发展这两个过程都是漫长的，饱含了许多代科学家们的辛酸努力。其中由计算机到人工智能，这一步更是里程碑似的。下面我将一一介绍。\par
\subsection{书本内容的概括}
第一章是电子计算机的诞生过程。在电子计算机诞生之前，还有各式各样的不同种计算机，先是机械型的计算机，其中英国数学家巴贝奇发明的分差机中出现现代计算机中的寄存器、运算器和控制器雏形，对计算机的发展有重要意义。然后到了电式计算机，其中德国科学家朱斯发明的二进制Z—1型计算机采用了二进制，到了Z—3型计算机室程序控制的，更是意义重大。\par
到了1946年，世界上第一台电子计算机诞生，这台计算机叫做ENIAC，是在美国宾夕法尼亚大学诞生的。这样电子计算机诞生在这个世界了。第二是电子计算机的发展。电子计算机发展至今，已经更新换代多次了，现在我们使用的是四代电子计算机。电子计算机主要按照电子器件的改变来划分其代数，第一代的电子计算机采用的电子器件是电子管。第二代采用的是晶体管。第三代电子计算机的主要标志是逻辑元器件采用了集成电路。第四代则是大规模集成电路。电子计算机的发展并没有止步，如今第五代已经在研发当中。\par
计算机科学导论》教材的主要内容。计算机科学导论是学习计算机知识的入门知识，同时也是我们计算机专业的核心课程之一。\par
第一章的主要内容是关于计算科学以及本教材的使用注意事项。第二章的内容是计算科学的基本概念和基本知识。分成十三部分来解释。分别是计算模型与二进制，存储程序式计算机的基本结构和工作原理，数字逻辑与集成电路，机器指令与汇编语言，算法过程与程序，高级语言程序设计与算法，系统软件与应用软件，计算机图形学，图像处理与模式识别，逻辑与人工智能，计算机组织与体系结构，并行计算机，通道与并行计算，计算机网络与通信以及最后的高性能计算。
第三章主要讲的是计算科学：它的意义，内容和用法。这一章节分为十二个部分来说明的。分别是什么是计算科学，本学科的基本问题，计算科学发展主线，计算科学的分类和分支学科简介，计算科学与数学和其他学科的关系，范型及其科学意义，计算科学的形态与核心概念，计算科学的典型方法和典型实例，学科基本工作流程方式及其科学意义，计算科学学科特点，发展规律，趋势及其社会影响，计算科学组织结构及其演变，计算机产业发展前景。\par
第四章的主要内容是关于如何学习计算科学和健康成长。这章主要分为四部分内容。分别是计算科学专业的培养规格和目标，一个计算科学专业参考教学计划与课程体系，如何学习计算科学和顺利完成学业，理解科学和科学素养。\par
第五章是布尔代数基础。分别是关于集合的基本概念与基本运算以及自对偶的公理系统。而自对偶的公理系统又分为布尔代数公理系统和标准形式和公理系统的完备性\citep{jisuankexuedaolun}\par

\subsection{对计算机专业的认识和体会}
（1） 计算机语言  \par
随着20世纪40年代第一台存储程序式通用电子计算机的研制成功，进入20世纪50年代后，计算机的发展步入了实用化的阶段。然而，在最初的应用中，人们普遍感到使用机器指令编制程序不仅效率低下，而且十分别扭，也不利于交流和软件维护，复杂程序查找错误尤其困难，因此，软件开发急需一种高级的类似于自然语言那样的程序设计语言。1952年，第一个程序设计语言Short Code出现。两年后，Fortran问世。作为一种面向科学计算的高级程序设计语言，Fortran的最大功绩在于牢固地树立了高级语言的地位，并使之成为世界通用的程序设计语言。Algol60的诞生是计算机语言的研究成为一门科学的标志。该语言的文本中提出了一整套的新概念，如变量的类型说明和作用域规则、过程的递归性及参数传递机制等。而且，它是第一个用严格的语法规则——巴科斯范式（BNF）定义语言文法的高级语言。程序设计语言的研究与发展在产生了一批成功的高级语言之后，其进一步的发展开始受到程序设计思想、方法和技术的影响，也开始受到程序理论、软件工程、人工智能等许多方面特别是实用化方面的影响。在“软件危机”的争论日渐平息的同时，一些设计准则开始为大多数人所接受，并在后续出现的各种高级语言中得到体现。例如，用于支持结构化程序设计的PASCAL语言，适合于军队各方面应用的大型通用程序设计语言ADA，支持并发程序设计的MODULA-2，支持逻辑程序设计的PROLOG语言，支持人工智能程序设计的LISP语言，支持面积对象程序变换的SMALLTALK、C等。而且，伴随着这些语言的出现和发展，产生了一大批为解决语言的编译和应用中所出现的问题而发展的理论、方法和技术。有大量的学术论文可以证明，由高级语言的发展派生的各种思想、方法、理论和技术触及到了计算机科学的大名数学科方向，但内容上仍相对集中在语言、计算模型和软件开发方法学方面。\par
(2)计算机模型与软件开发方法\par
20世纪80年代是计算机网络、分布式处理和多媒体大发展的时期。在各种高级程序设计语言中增加并发机构以支持分布式程序设计，在语言中通过扩展绘图子程序以支持计算机图形学程序设计成为当时程序设计语言的一种时尚。之后，在模数/数模转换等接口技术和数据库技术的支持下，通过扩展高级语言的程序库又实现了多媒体程序设计的构想。进入20世纪90年代之后，并行计算机和分布式大规模异质计算机网络的发展又将并行程序设计语言、并行编译程序、并行操作系统、并行与分布式数据库系统等试行软件的开发的关键技术依然与高级语言和计算模型密切相关，如各种并行、并发程序设计语言，进程代数，PETRI 网等，它们正是软件开发方法和技术的研究中支持不同阶段软件开发的程序设计语言和支持这些软件开发方法(2)计算机模型与软件开发方法，20世纪80年代是计算机网络、分布式处理和多媒体大发展的时期。在各种高级程序设计语言中增加并发机构以支持分布式程序设计，在语言中通过扩展绘图子程序以支持计算机图形学程序设计成为当时程序设计语言的一种时尚。之后，在模数/数模转换等接口技术\par
(3)关于计算机专业的进一步思考\par
计算机的发明与应用，其根本目的是在于代替人的各种劳动，科学研究特别是军工领域内的尖端科技研发中大量复杂，繁琐的计算任务极大地促进了电子数字计算机的研制。第一台电子数字计算机诞生后,一些人开始考虑让计算机具有某种思维能力，以便让它像一-个训练有素的人一样能做一些需要一定的思维，推理的工作。对于这样一个美好的愿望，人们自然很容易想到首先让计算机模拟人来下棋，证明和发现数学定理或做语言翻译之类的事情，并且也确实有- -些在当时看来属于惊人的发现和成功，这些应该是人工智能研发的开端。但是受限于当时的科学技术水平和认知，无法实现实质性的突破。人工智能(Artificial Intelligence)，英文缩写为Al。它是研究、开发用于模拟，延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。人工智能是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器，该领域的研究包括机器人、语言识别、图像识别、自然语言处理和专家系统等。人工智能从诞生以来，理论和技术日益成熟，应用领域也不断扩大，可以设想，未来人工智能带来的科技产品，将会是人类智慧的“容器”。人工智能可以对人的意识、思维的信息过程的模拟。人工智能不是人的智能，但能像人那样思考、也可能超过人的智能。\par
人工智能是一门极富挑战性的科学，从事这项工作的人必须懂得计算机知识，心理学和哲学。人工智能是包括十分广泛的科学，它由不同的领域组成，如机器学习，计算机视觉等等，总的说来，人工智能研究的一个主要目标是使机器能够胜任-些通常需要人类智能才能完成的复杂工作。但不同的时代、不同的人对这种"复杂工作”的理解是不同的。20世纪中叶，以英国数学家图灵为代表的一代科学家为，人工智能学科的诞生提供了理论基础和实验工具。1956年 ，达特茅斯会议标志着人工智能学科的正式诞生，以冯.诺依曼、图灵为首的科学家试图通过符号化编程实现人工智能。20世纪60年代以来,人工智能研究随着技术水平的发展,在瓶颈与突破中曲折前进。20世纪末，由于硬件能力不足、算法缺陷等原因,人工智能技术陷入发展低迷期。而进入21世纪以来，大数据、云计算等信息技术给人工智能发展带来了新机遇,成本低廉的大规模并行计算、大数据、深度学习算法、人脑芯片4大催化剂引|领人工智能的发展出现.上行趋势,同时人工智能的发展也给新一代信息技术与工业各领域渗透融合提供了新的动力。近年来,全球人工智能技术和产业进入了新一轮快速发展期，大批创新人工智能应用和人工智能公司正在崛起。国际IT 巨头通过大量收购新创公司、网罗顶尖人才、加大投资力度，力图抢占行业制高点,把握主导权。机器学习、自然语言处理、计算机视觉等AI细分领域近期进展显著，很多新的应用和产品已经惊艳亮相各国高科技企业普遍将人工智能视为下一代产业革命和互联网革命的技术引爆点，并且注入大量资金以加快其产业化进程。其中IBM、谷歌、Facebook、 微软、苹果、Amazon等国际IT巨头最具影响力。\par
IBM公司近年建立了认知计算系统Watson,旨在借其衍生出巨大的智能顾问市场。同时,IBM正在研究-种新型仿生芯片，实现电脑模仿人脑运算的过程。谷歌在2013年完成对8家机器人相关企业的收购工作,并在机器学习方面大量搜罗企业与人才。自2015年3月起，谷歌先后宣布在医药研发、无人驾驶汽车、血糖实时监测隐形眼镜、即时翻译摄像头、聊天机器人等方面取得显著成果,同时计划将人工智能研发成果与其搜索引擎、广告、视频网站和电子商务等核心业务结合起来。Facebook在人工智能领域的布局主安围绕其用户的社交关系和社交信息展开，并采用全球领先的图像识别技术和自然语言处理技术。2013年Facebook成立了人工智能实验室，于2016年四月发布了能够向盲人扫面图像的图像识别系统。同时，将“社交虚拟实现”作为一项核心业务，投入数百位顶级工程师。微软着力于Cortana智能助理系统的开发,在2015年还展示Skype语言转换系统。另外，苹果的Siri智能助理、Amazon的机器人飞行器等项目对人工智能的发展都产生了巨大影响。韩国和日本的各大公司纷纷把机器人技术移植到制造业新领域并尝试进入服务业。我国人工智能研究起步晚，研究水平与发达国家存在明显差距，但已引起国内专家学者的广泛关注。2016年5月,国家发改委、科技部、工业和信息化部、中央网信办在《“互联网+”人工智能三年行动实施方案》提出，到2018年,初步建成基础坚实、创新活跃、开放协作、绿色安全的人工智能产业生态,形成千亿级的人工智能市场应用规模。从企业层面来看,随着互联网技术瓶颈的凸显,将业界的视线聚焦到人工智能产业以寻求突破,但总体上国内人工智能产业还处于野蛮生长的初期阶段。但现在看来，人工智能(Artificial Intellgence)有了发展的契机。\par
\subsection{导论的进一步思考}
导论从计算科学一词的来历开始介绍，依次介绍了科学哲学与学科方法论，一般的科学思想方法，计算模型与二进制，存储程序式计算机的基本构造和工作原理，数学逻辑与集成电路，机器指令与汇编语言，算法过程与程序，高级语言，程序设计技术与方法，系统软件与应用软件，计算机图形学，图象处理与模式识别，逻辑与人工智能，计算机组织与体系结构，并行计算机通道与并行计算，计算机网络与通信，高性能计算以及学科的基本问题，计算学科的学科形态与核心形态与核心概念，计算科学的典型方法与典型实例，学科基本工作流程方式及学科意义，计算科学学科特点，发展规律，趋势及其社会影响。计算科学组织结构及其演变，计算机产业发展前景以及如何学习计算科学与健康成长。这些对计算学科全方位的介绍，以及各章节中贯穿的科学哲学和学科方法论，虽然浅尝辄止，但让初学者甘之如饴，建立起对本学科认识的基本品导论从计算科学一词的来历开始介绍，依次介绍了科学哲学与学科方法论，一般的科学思想方法，计算模型与二进制，存储程序式计算机的基本构造和工作原理，数学逻辑与集成电路，机器指令与汇编语言，算法过程与程序，高级语言，程序设计技术与方法，系统软件与应用软件，计算机图形学，图象处理与模式识别，逻辑与人工智能，计算机组织与体系结构，并行计算机通道与并行计算，计算机网络与通信，高性能计算以及学科的基本问题，计算学科的学科形态与核心形态与核心概念，计算科学的典型方法与典型实例，学科基本工作流程方式及学科意义，计算科学学科特点，发展规律，趋势及其社会影响。计算科学组织结构及其演变，计算机产业发展前景以及如何学习计算科学与健康成长。这些对计算学科全方位的介绍，以及各章节中贯穿的科学哲学和学科方法论，虽然浅尝辄止，但让初学者甘之如饴，建立起对本学科认识的基本框架，激发兴趣。\par
任何一门门学科学科或专业,都含有丰富的人文内容和特质，都可以进行人文教育,使学生在学习中感受到美的熏陶与生命力量的提升，在计算学科导论的教学过程中，以一种什么样的意义来揭示该学科,就帮助学生设置-一个学习的方向。方向不同，学生在从事学习过程中进行的心理活动不同，学习的结果也不同。对知识，学生会记忆性地学，对技能，学生会模仿性地学，对能力方面，学生会思维地学,对伦理方面，学生会体验地学。无论如何，教学过程中的引导作用是非常明显也是极其重要的。并且相信几乎占据导论“半壁江山”的学科意义，内容，方法，健康成长是任意一本专业书都不会出现的。也就是说，本书是为了培养高素质的计算机科学与技术专业人才的一个导引。在通识教育观下，引导初学者具备高素质人才的条件。\citep{jisuankexuedaolunzhongderenwensuzhijiaoyu}\par
\begin{itemize}
\item1.具有高尚的品德和良好的人文素养。
\item2.具有坚实的专业基础和深厚的专业功底。
\item3.具有创新意识，具有科学的思想方法。
\end{itemize}
以上就是我对计算科学导论和人工智能的一些认识。\par
\section{有关决策树的进一步思考}
首先，我们简单介绍一下决策树。
决策树算法是机器学习里的一种分类方法。要了解决策树，我们将其分为三个方面来分开了解。
\begin{itemize}
\item1.什么是决策树。
\item2.了解决策树所需要的数学基础。
\item3.关于决策树的其他方面。
\end{itemize}
1.首先，什么是决策树？决策树是一种基本的分类与回归方法。这里我们主要讨论用于分类的决策树，它可以用于机器学习中的决策树训练，使用决策树作为预测模型来预测样本的类标。\par
它的准确定义为：分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点和有向边组成。结点有两种类型：内部结点和叶结点。内部结点表示一个特征和属性，叶结点表示一个类。\par
可以将决策树看成一个if-then规则的集合。过程：路径上内部结点的特征对应着规则的条件，而叶结点的类对应着规则的结论。\par
2.然后是了解决策树所需要的基础\par
信息熵的有关概念：1948年，香农提出了“信息熵”的概念： 一条信息的信息量大小和它的不确定性有直接的关系，要搞清楚一件非常不确定的事情，或者是我们一无所知的事情，需要了解大量信息。信息量的度量就等于不确定性的多少 一个离散型随机变量X的熵H(X)定义为：H(x)=-$ \sum_{x=i}^n $p(x)$ \log $p(x)熵的范围是【0,1】。
我们通常用比特（bit）来衡量信息的多少。\citep{tongjixuexifangfa}\par


\begin{figure}[h!]
	\centering
	\includegraphics[scale=1.2]{picture1}
	\caption{picture1}
	\label{fig:picture1}
\end{figure}


\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{picture2}
	\caption{picture2}
	\label{fig:picture2}
\end{figure}



3.(1)随机森林算法梳理\par
集成学习的概念\par
集成学习使用多个分类器，发挥各个个体学习器的优点，实现多样性，从而实现较好的拟合效果。目前分位三种继承学习：boosting、bagging以及stacking。\par
个体学习器的概念\par
个体学习器是集成学习中的子概念，是指集成学习中使用的子学习器。个体学习器需要保持多样性，这样才能发挥集成学习的优势。
怎么样发挥个体学习器的多样性呢？\par
*增加数据样本扰动。对于不稳定的个体学习器有较好的效果，比如决策树和神经网络。而对于稳定的个体学习器线性（学习器、支持向量机、朴素贝叶斯、K近邻学习器），就没有好的效果了。\par
*输入属性扰动。就是将输入样本的属性空间分称多个子属性空间，再基于每个子属性空间训练学习器，这样不仅能获得多样性好的子学习器，而且还会降低训练时间。\par
*输出表示扰动。基本思路是对输出表示进行操纵以增强多样性。可对训练样本的类标记稍作变动，如“翻转法”，翻转法由Breiman在2000年随机改变一些训练样本的标记；或者是对输出表示进行转化，如“输出调制法”将分类输出转化为回归输出后构建个体学习器。还可以将原任务拆解为多个可同时求解的子任务。\par
*算法参数扰动。这里的算法参数一般要对参数进行设置，比如神经网络的隐层神经元数、初始连接权值等，通过随机设置不同的参数，往往可产生差别较大的个体学习器。比如可以将决策树使用的属性选择机制替换为其他的属性选择机制。“负相关法”显示地通过正则化项来强制个体神经网络使用不同的参数。\par
boosting bagging的概念、异同点\par
boosting是使用一系列弱分类器来集成的。经典算法有：Adaboost、GBDT、XGBoost。boost是串行的。Adaboost是根据当前学习器的学习结果，对于误差较大的样本增强权重。GBDT和XGBoost都是拟合残差的算法。\par
bagging算法就是并行训练一堆学习器。经典算法：随机森林。\par
Stacking模型：聚合多个分类或回归模型（可以分阶段来做）。\par
理解不同的结合策略(平均法，投票法，学习法)

平均法：对数值型输出，最常见的结合策略是使用平均法。有简单平均法和加权平均法。（1）规模大的集成，学习的权重较多，加权平均法易导致过拟合；（2）个体学习器性能相差较大时宜使用加权平均法，相近用简单平均法\par
投票法：（1）绝对多数投票法：某标记超过半数;（2）相对多数投票法：预测为得票最多的标记，若同时有多个标记的票最高，则从中随机选取一个。 (3）加权投票法：提供了预测结果，与加权平均法类似。\par
学习法：分为初级学习器和次级学习器。次级学习器是用来学习初级学习器的结合策略的。次级学习器的输入是初级学习器的输出，从而确定结合策略。\par
输入：训练集D=(x1,y1),(x2,y2),...,(xm,ym); \par
初级学习算法：Λ1,Λ2,...,ΛT;\par
次级学习算法：Λ\par
过程： \par
1、for t=1,2,...,T do\par
2、	ht=Λt(D); \par
3、end for\par
4、D‘=∅\par
5、for i=1,2,...,m do\par
6、	for t=1,2,...,T do\par
7、		zit=ht(xi);\par
8、	endfor\par
9、	D′=D′⋃((zi1,zi2,...,ziT),yi);\par
10、endfor\par
11、h′=Λ(D′);\par
输出：H(x)=h′(h1(x),h2(x),...,hT(x))\par
随机森林的思想\par
(1)数据采样随机。给定一个训练样本集，数量为N，我们使用有放回采样到N个样本，构成一个新的训练集。注意这里是有放回的采样，所以会采样到重复的样本。详细来说，就是采样N次，每次采样一个，放回，继续采样。即得到了N个样本。\par
(2)特征选择随机 （可以命名为二重随机性）。在构建决策树的时候，我们前面已经讲过如何在一个节点上，计算所有特征的InformationGain（ID3） 或者 GainRatio（C4.5），然后选择一个最大增益的特征作为划分下一个子节点的走向。 但是，在随机森林中，我们不计算所有特征的增益，而是从总量为M的特征向量中，随机选择m个特征，其中m可以等于sqrt(M)，然后计算m个特征的增益，选择最优特征（属性）。注意，这里的随机选择特征是无放回的选择！\par
随机森林的优缺点\par
优点：（1）它能够处理很高维度（ feature很多）的数据，并且不用做特征选择；（2） 由于随机选择样本导致的每次学习决策树使用不同训练集，所以可以一定程度上避免过拟合；\par
缺点：（1）随机森林已经被证明在某些噪音较大的分类或回归问题上会过拟合；（2）对于有不同级别的属性的数据，级别划分较多的属性会对随机森林产生更大的影响，所以随机森林在这种数据上产出的属性权值是不可信的。\par
随机森林在sklearn中的参数解释\par
(1)splitter:特征切分点选择标准，决策树是递归地选择最优切分点，spliter是用来指明在哪个集合上来递归，有“best”和“random”两种参数可以选择，best表示在所有特征上递归，适用于数据集较小的时候，random表示随机选择一部分特征进行递归，适用于数据集较大的时候。\par
(2)max-depth:决策树最大深度，决策树模型先对所有数据集进行切分，再在子数据集上继续循环这个切分过程，max-depth可以理解成用来限制这个循环次数。\par
(3)min-samples-split:子数据集再切分需要的最小样本量，默认是2，如果子数据样本量小于2时，则不再进行下一步切分。如果数据量较小，使用默认值就可，如果数据量较大，为降低计算量，应该把这个值增大，即限制子数据集的切分次数。\par
(4)min-samples-leaf:叶节点（子数据集）最小样本数，如果子数据集中的样本数小于这个值，那么该叶节点和其兄弟节点都会被剪枝（去掉），该值默认为1。\par
(5)min-weight-fraction-leaf:在叶节点处的所有输入样本权重总和的最小加权分数，如果不输入则表示所有的叶节点的权重是一致的。\par
(6)max-features:特征切分时考虑的最大特征数量，默认是对所有特征进行切分，也可以传入int类型的值，表示具体的特征个数；也可以是浮点数，则表示特征个数的百分比；还可以是sqrt,表示总特征数的平方根；也可以是log2，表示总特征数的log个特征。\par
(7)random-state:随机种子的设置，与LR中参数一致。\par
(8)max-leaf-nodes:最大叶节点个数，即数据集切分成子数据集的最大个数。\par
(9)min-impurity-decrease:切分点不纯度最小减少程度，如果某个结点的不纯度减少小于这个值，那么该切分点就会被移除。\par
(10)min-impurity-split:切分点最小不纯度，用来限制数据集的继续切分（决策树的生成），如果某个节点的不纯度（可以理解为分类错误率）小于这个阈值，那么该点的数据将不再进行切分。\par
(11)class-weight:权重设置，主要是用于处理不平衡样本，与LR模型中的参数一致，可以自定义类别权重，也可以直接使用balanced参数值进行不平衡样本处理。\par
(12)n-estimators:随机森林中树的棵树，默认是10棵。
criterion:样本集切分策略，默认是gini指数，此时树模型为CART模型，当值选为信息增益的时候，模型就成了ID3模型，默认为CART模型。\par
(13)bootstrap:是统计学中的一种重采样技术，可以简单理解成是有放回地抽样，默认是True,即采取有放回抽样这种策略，这不就是bagging的思想么。\par
(14)oob-score:袋外估计(out-of-bag)，这个外是针对于bagging这个袋子而言的，我们知道，bagging采取的随机抽样的方式去建立树模型，那么那些未被抽取到的样本集，也就是未参与建立树模型的数据集就是袋外数据集，我们就可以用这部分数据集去验证模型效果，默认值为False。\par
随机森林的应用场景\par
（1） 由于随机性，对于降低模型的方差很有作用，故随机森林一般不需要额外做剪枝，即可以取得较好的泛化能力和抗过拟合能力（Low Variance）。当然对于训练集的拟合程度就会差一些，也就是模型的偏倚会大一些（High Bias），仅仅是相对的。\par
(2)不要求是linear features (do not expect linear features or even features that interact linearly), 比如LR很难处理categorical features，而Tree Ensembles，是一些决策树的集合，可以很容易得处理这些情况
由于算法构建的过程(bagging or boosting)，这类算法很容易处理高维的数据，大量的训练数据的场景。\par
overfitting\par
在决策树算法中，用剪枝来避免过度拟合。过度拟合是因为样本属性太多，造成分类太过细化。这样可能会导致，模型在样本数据中适应得非常好，但在未知数据中，适应得就非常不好。所以我们需要用剪枝来解决这个问题。剪枝就是去除一些信息增益较少的数据，以此来避免过度细化。\par
基于决策树算法的大数据处理技术优化\par
1.特征值优化算法\par
特征值优化算法是指在原有的集合中将
数据重新分类，然后形成一个数据子集，对数
据子集进行处理分析。特征值优化算法原理较
为简单，并且在实践中应用较为简便。利用特
征选择值进行算法计算主要可以分为两类，一
种是筛选器，一种是封装器。筛选器是指集合
内部信息衡量，然后独立于分类算法，这是一
个预处理过程。通过相关系数标本进行评价，
以达到数据处理的目的。\par
2.集中优化算法\par
集中优化算法适用于处理数据集合等较
为庞大的计算模式，对其内存进行计算过程中
没有方法将全部数据内容一次性处理完毕，因
此许多数据需要暂时存放在存储器之中。由于
决速算法自身的读写操作，因此读写速度比较
缓慢，比较适合对这种决策树算法采取优化措
施。减少其读写操作的程序成为了决策树算法
进行优化的主要方向。在这其中 SICU 就是一
种主要的优化算法，这种优化算法通过使用广
度排序以及优先原则来达到减少存储器内部读
写出生的目的，并且极大提高拳速算法的整体
效率，除此之外还有 boat 算法的优化。\par
3.分布式的计算方法\par
分布式计算方法对其子集进行了扩展，
因此在数据处理能力上达到了空前的提高，他
能够有效加快数据读取数据的整体能力，并且
提高运行的整体速度，因此分布式算法开发比
较早。此后谷歌开发了相应的可扩展式的计算
机框架，这个计算机框架以控制器作为其整体
的核心，然后对决策树进行调控。调控的主要
目的是利用大数据模型来进行整体的训练。同
时控制器能够有效接入计算机群中，在学习决
策树模型中集成方法也可以解决大数据分布式
的问题。\par
4.面向流数据的整体优化算法\par
流数据整体优化算法可以作为大数据的
源头，同时对于叶子阶段相关的统计信息能够
有效进行处理，用于代替中间的决策节点，形
成新的决策树。在数据整体路以后实现节点分
类处理。它能够有效实现统计信息的更新。面
向流数据的整体优化算法使得时间成本得到优
化，但是其自身的缺点也很明显，缺乏连续处理素质的能力，同时还可能出现数据的漂流情况。最终的情况会导致大数据信息处理数据准
确度有所降低。但是随着现代研究的深入，面
向流数据的整体优化算法能够有效支持数值属
性的优化处理，因此预测的整体准确性得到了
充分的提高，在大数据分析和处理中得到了广
泛的应用。\citep{guodunihedejianzhifangfa}\par
决策树算法与遗传算法的神经网络研究及其应用\par
当今社会人类所存储的数据是成千上万的,如何能够更有效的利用好这些信息已经越来越受到人们的重视。而数据挖掘正是一种从数据中提取有用的信息,并将之应用于各个行业的方法。本文首先对数据挖掘中受到广泛关注的决策树算法、遗传算法和神经网络算法进行了综述,描述了各算法的具体实现过程及步骤。然后通过分析决策树算法与神经网络算法的特点,将它们进行有效得结合,提出一种基于决策树的神经网络权值初始化算法。该算法利用决策树算法,通过分析各样本数据来确定神经网络的初始权值,与传统的神经网络算法比起来,该方法极大的缩小了神经网络初始权值的随机性,使其更有利于最优神经网络模型的生成。最后将该算法应用到了一个通过分析企业类型、注册资金、盈利比例来判断企业信誉的例子中,并通过Matlab编程来实现。文章的第四部分提出的是一种基于遗传算法的神经网络结构优化算法。该算法将遗传算法与神经网络算法进行了巧妙的结合,它利用遗传算法解决了神经网络算法中比较难的结构优化问题,而反过来又巧妙的运用神经网络算法回避了遗传算法中如何确定衡量函数的问题。同样也将该算法应用到了一个超市满意度的例子中,并运用Matlab编程来具体实现了该基于遗传算法的神经网络结构优化算法。\par
\section{总结}
通过这次课程总结报告，我查阅了许多的资料，对计算科学导论，人工智能以及决策树算法有了进一步的认识。并且，我希望通过进一步的学习能够了解更多。\par
\section{附录}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{Q}
	\caption{}
	\label{fig:picture2}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{W}
	\caption{}
	\label{fig:picture2}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{E}
	\caption{}
	\label{fig:picture2}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{R}
	\caption{}
	\label{fig:picture2}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{T}
	\caption{}
	\label{fig:picture2}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.1]{Y}
	\caption{}
	\label{fig:picture2}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.1]{U}
	\caption{}
	\label{fig:picture2}
\end{figure}

\hspace*{\fill} \\

{\bf 注意，参考文献至少五篇，其中至少两篇为英文文献，参考文献必须在正文中有引用。}
\bibliographystyle{plain}
\bibliography{references}


\end{document}
